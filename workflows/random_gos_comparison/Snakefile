import itertools
import matplotlib
matplotlib.use('Agg')
import os
import pandas as pd
import re
import seaborn as sns

from megago.constants import UNIPROT_ASSOCIATIONS_FILE_PATH
from pathlib import Path

SAMPLESIZES = [100, 200, 400, 800, 1600, 3200, 6400]
REPLICATES = 5

rule all:
    input:
        "similarity.svg"

rule create_random_samples:
    input:
         UNIPROT_ASSOCIATIONS_FILE_PATH
    output:
         expand("go_terms/n{{samplesize}}/r{{replicate}}/{i}.csv", i=[0,1])
    run:
        import pandas as pd
        import random
        from megago.constants import UNIPROT_ASSOCIATIONS_FILE_PATH

        REPLICATE_NO = int(wildcards.replicate)
        SAMPLESIZE = int(wildcards.samplesize)

        s = pd.read_csv(UNIPROT_ASSOCIATIONS_FILE_PATH, sep="\t", usecols=[1], squeeze=True, dtype=str)

        s.dropna(inplace=True)

        s_l = s.apply(lambda x: x.split(";")[:-1])

        l_gos = [e for l in s_l.to_list() for e in l]
        random.seed(f"123-{SAMPLESIZE}-{REPLICATE_NO}")
        for i in output:
            with open(i, "w") as f_out:
                f_out.write("random gos are awesome!\n")
                go_rand = random.choices(l_gos, k=SAMPLESIZE)
                f_out.write("\n".join(go_rand))

rule calc_pairwise_sample_similarity:
    input:
        # "go_terms/n{{samplesize}}/r{{replicate}}/{i}.csv"
        "go_terms/n{samplesize}/r{replicate}/0.csv",
        "go_terms/n{samplesize}/r{replicate}/1.csv"
    output:
        "similarity/n{samplesize}/r{replicate}.csv"
    log: "similarity/n{samplesize}/r{replicate}.log"
    shell:
        "megago --log {log} {input} > {output}"

rule aggregate_similaries:
    input:
        # "similarity/n{samplesize}/r{replicate}.csv"
        lambda w: [f"similarity/n{w.samplesize}/r{replicate}.csv"
                   for replicate in range(int(w.replicates))]
    output:
        "aggregated_sim/n{samplesize}-r{replicates}.csv"
    run:
        namespaces = ["molecular_function", "biological_process", "cellular_component"]
        l_replicates = sorted(list(range(int(wildcards.replicates))))
        df = pd.DataFrame(index=l_replicates, columns=namespaces)
        for r, f_in in enumerate(input):
            df_s = pd.read_csv(f_in, index_col=0)
            for namespace in namespaces:
                sim = df_s.loc[namespace, "SIMILARITY"]
                df.loc[r, namespace] = sim
        df.to_csv(output[0])

rule visualization:
    input:
        expand("aggregated_sim/n{samplesize}-r{replicates}.csv", samplesize=SAMPLESIZES, replicates=REPLICATES)
    output:
        "similarity.svg"
    run:
        l_dfs = []
        for f in input:
            size = int(re.match(r"aggregated_sim/n(\d+)-r\d+\.csv" ,f).group(1))
            df_i = pd.read_csv(f)
            df_i.rename(columns={df_i.columns[0]: "replicate"}, inplace=True)
            df_i["sample_size"] = size

            l_dfs.append(df_i)
        df = pd.concat(l_dfs, ignore_index=True)

        data = pd.melt(df, id_vars=["replicate", "sample_size"], value_vars=df.columns[1:4], value_name="similarity",
               var_name="namespace")

        stripplot = sns.stripplot(x="sample_size", y="similarity", hue="namespace", data=data)
        stripplot.get_figure().savefig(output[0])
